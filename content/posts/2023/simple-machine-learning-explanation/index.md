---
title: یادگیری ماشین به زبان ساده
date: 2023-09-17
fatags:
  - آموزشی
  - یادگیری_ماشین
  - تکنولوژی
math: "true"
---
- انقدر که میگن یادگیری ماشین منظورشون چیه؟ 
- بالاخره تو هوش‌مصنوعی دارید چیکار می‌کنید؟ ربات درست می‌کنید؟ 

دوست دارم قبل از اون بگم که ادعایی در این زمینه ندارم. ادعا رو اون کسی می‌تونه داشته باشه که حداقل ۴ ۵ سال تو یک حوزه‌ای کار کرده باشه و سرد و گرم‌اش رو چشیده باشه. قبل از اون هر چی هست، «‌خاک‌بازی» هست. 

به هر حال. 
### هوش مصنوعی

چند بار اتفاق افتاده که بخوام راجع به هوش‌مصنوعی به کسانی که هیچی در این حوزه نمی‌دونند توضیح بدم.  بالاخره چون می‌خوام به زبان ساده بگم از دقت علمی کم میشه ولی سعی می‌کنم تا حد امکان مفهوم رو برسونم. امیدوارم که بتونم. 

سوالاتی که می‌خوام بهشون جواب بدم:
- هوش مصنوعی چیه؟
- یادگیری ماشین چیه؟
- دقیقا چه چیزی رو یاد می‌گیریم؟ 
- مدل چیه؟

کلا تو هوش مصنوعی سعی‌ بر این هست که کارهایی که به ماشین یاد بدیم که با برنامه‌نویسی به شیوه معمول نمیشه بهش یاد داد یا بسیار بسیار سخته. این کارها اکثراً همون کارهایی هستند که برای ما بصورت شهودی آسون هستند ولی برای کامپیوتر سخته. 

مثلا تشخیص گربه از شتر برای یک کودک خیلی ساده است. کافیه چند تا مثال ببینه. ولی برای یک کامپیوتر تسک بسیار سختی هست (بود). علتش هم اینه که اینطور چیزها رو نمیشه با قاعده و قانون به ماشین یاد داد. کلاً کامپیوتر تو کارهایی که آدمیزاد در انجام‌شون چندان خوب نیست، خیلی خوب عمل می‌کنه. در عوض تو کارهایی که آدمیزاد به سادگی (به صورت غریزی) انجام میده بسیار ناتوان هست.

حالا هوش مصنوعی تلاشی هست برای حل این مشکلات. روشش هم به جای روش‌های الگوریتمی کاملاً مشخص، یادگیری از داده هست. 

اینجا نکته مهم اینه که همه چیز رو نمی‌توان (و نباید) با هوش‌مصنوعی انجام داد. الگوریتمی که میشه به روش کلاسیک و سنتی انجام داد رو چرا باید هوش‌مصنوعی انجام بده؟ هوش مصنوعی قراره بهمون توانایی این رو بده که کارهایی که با برنامه‌نویسی کلاسیک نمی‌تونستیم انجام بدیم رو انجام بدیم. 

مثلاً انجام تراکنش‌های بانکی نیازی به هوش‌مصنوعی نداره. بدون هوش‌مصنوعی هم کارش رو به خوبی انجام میده؛ ولی تشخیص تقلب (Fraud Detection) در تراکنش نیاز به هوش‌مصنوعی داره. چون چندان بدیهی نیست و نمیشه بصورت مشخص گفت یک تراکنش تقلبی هست. 

مثلاً من تو تز ارشدم روی تشخیص پولیپ روده کار می‌کردم. شما نمی‌تونید دقیقاً بگید که چرا فلان بیمار پولیپ داره و براش الگوریتم کاملاً مشخص دربیارید. برای همین میایم از تصاویری که یک پزشک برچسب زده یک مدل در میاریم که بتونه پولیپ رو تشخیص بده. 

الان مدل‌ها انقدر خوب شدند که تقریباً میشه گفت تو یک تسک خاص از پزشک متخصص هم می‌تونند بهتر عمل کنند. 

### یادگیری ماشین

با این مقدمه، یادگیری ماشین تلاشی هست برای یاد گرفتن یک تابع. تابع تو ریاضی به رابطه‌ای میگیم که یک سری ورودی رو به یک خروجی نسبت بده. از اینجا به بعد با کمی ساده‌سازی مدل و تابع‌ رو به جای هم به کار می‌برم. 

مثلاً فرض کنید تابعی داشته باشیم که متراژ خونه و مساحت زیر بنا و تعداد اتاق و شماره منطقه رو بگیره و قیمت خونه رو تخمین بزنه. اینجا ورودی و خروجی کاملاً عددی هست و مشخص. اما بعضی جاها ممکنه ورودی خروجی انقدر واضح نباشه. چیزی که مهمه اینه که **همه چیز** قراره به عدد تبدیل بشه.  

مدل‌های هوش مصنوعی، تصویر و ویدئو و متن رو هم به صورت یک سری عدد می‌بینند. مثلا ممکنه متن «بابا آب داد» رو به شکل «۱۴۵۱ ۱۳۴۵۱ ۱۳۴۱» ببینند. فعلاً از من بپذیرید که هر چیزی در یادگیری ماشین قراره به روشی به عدد متناظرش تبدیل بشه و بعد روی اون پردازش‌های بعدی صورت بگیره. چیزی که اینجا می‌خوام توضیح بدم نحوه تبدیل متن به عدد یا تصویر به عدد (که بهش Embedding میگن) نیست. بلکه بیشتر روی اون تابع می‌خوام متمرکز بشم. 

یک نمونه خیلی ساده از این توابع، تابع رگرسیون خطی هست. چیز پیچیده‌ای هم نیست. یک خط ساده است که قطعاً تو دوران تحصیل به قیافه‌اش برخوردید. 
$$ y = ax + b $$
ولی این تابع فقط یک ورودی و خروجی داره. خب بیاید پیچیده‌ترش کنیم که حداقل به درد مسئله پیش‌بینی قیمت خونه بخوره (چون تو مسئله پیش‌بینی قیمت خونه سه تا ورودی داریم و یک خروجی):
$$ y = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_3 $$
الان بهتر شد. یک سری w هم داریم که برای وزن‌دهی‌شون استفاده کنیم. قاعدتاً تو انتخاب خونه، اهمیت تمام معیارها یکی نیست و یک معیار ممکنه خیلی مهم‌تر و کلیدی‌تر باشه. این w ها برای این ضرب شدند. 

ورودی ها که مشخصه. خروجی هم مشخصه. مدل هم یک مدل خطی ساده است. حالا وزن‌ها رو چطوری تعیین کنیم؟ یک راهکار اینه که یک متخصص قیمت‌دهی خانه پیدا کنیم و بهش بگیم که بره برامون فرمولش رو دقیق دربیاره. اونم مثلا همچین چیزی رو بهمون میگه:
$$ y = 40 + 0.3 x_1 + 0.5 x_2 + 5 x_3 $$
همین میشه یک نمونه ساده از مدل که می‌تونه برای پیش‌بینی قیمت خونه به کار بره. 

یک راه منطقی‌تر اینه که بریم یک عالمه مشخصات خونه‌های مختلف داخل تهران رو استخراج کنیم و بعد سعی کنیم با روش‌های بهینه‌سازی بهترین وزن‌هایی رو پیدا کنیم که با کمترین خطا بتونند قیمت رو پیش‌بینی کنند. 

به این کار میگیم «آموزش دادن مدل» یا «**Train کردن**». در واقع مدلی که Train شده یک سری وزن (ضرایب ایکس) رو یاد گرفته که می‌تونند برای پیش‌بینی استفاده بشن. 

بعدا در زمان تست مدل، تنها کاری که باید بکنیم اینه که ورودی‌ها رو به مدل از قبل آموزش دیده بدیم و خروجی رو تحویل بگیریم. 

حالا بیاید پیچیده‌‌تر فکر کنیم. مدلی که داریم خیلی ساده است. نظرتون چیه اگر توان دو یک سری وزن‌ها رو هم اضافه کنیم؟ به نظرتون مدل بهتر میشه؟ 
$$ y = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_3 + w_1 x_1^2 + w_2 x_2^2 + w_3 x_3^2 $$
یا مثلا می‌تونیم یک علامت رادیکال بالای یک سری پارامتر‌ها بگذاریم و یک سری مدل دیگه داشته باشیم. حتی میشه کل عبارت رو برد زیر جناب رادیکال! 

آیا هر تابعی که دوست داشتیم رو می‌تونیم بگذاریم؟ بله به شرط‌ها و شروط‌ها. شما می‌تونید هر چیزی خوشتون اومد بذارید که یک مدل بدست بیاد. ولی باید بتونید پارامترهای بهینه برای مدل‌تون بدست بیارید.   

حتی می‌تونیم توابع مختلف رو با هم ترکیب کنیم. مثلاً می‌تونیم بگیم:
$$ z =  \frac{1}{1+e^{-y}} $$
در اینجا من خروجی تابع قبل یا همون y رو در این تابع می‌گذارم و z بدست میاد. 

شاید بگید خب که چی؟ مسئله اینه که هر تابعی خواص خودش رو داره. مثلاً تابع بالا اسمش تابع Sigmoid هست و دامنه خروجی محدود می‌کنه که بین صفر و یک باشه. همین رو می‌تونیم برای جاهایی که نیاز داریم خروجی‌مون یک احتمال باشه استفاده کنیم. 

شما الان با دو تا از ساده‌ترین مدل‌های یادگیری ماشین آشنا شدید. به مدل اول (مدل خطی) میگن رگرسیون خطی و به مدل دوم میگن Logistic Regression. 

اینجا سؤال پیش میاد که اگر ساختن یک مدل جدید به همین سادگی هست که بساط منقل پهن کنیم و در تخیلات‌مون به یک تابع فضایی در ابعاد بالا (!) فکر کنیم، پس چرا مدل‌های هوش‌مصنوعی انقدر محدود هستند؟ (مثلاً چرا میلیاردها مدل وجود ندارند).

به نظرم جواب اینه که لزومی نداره که مدلی که من و شما نشستیم فرمول براش ابداع کردیم تو واقعیت هم خوب عمل کنه. در واقع خیلی از مدل‌هایی که بهش فکر می‌کنیم به درد نمی‌خورند. برای بعضی از مدل‌ها هم نمیشه وزن‌های مناسب رو استخراج کرد و فرآیند Train کردن‌شون خیلی سخته. 

پس چیکار کنیم؟

جامعه یادگیری ماشین (منظورم از جامعه Community هست) کم‌کم به این نتیجه رسیدند که بهتره با توجه به مسئله تصمیم‌گیری بشه که چه مدلی براش مناسب هست. 

پس اومدند مسائل مختلف تعریف کردند و سعی کردند مسائل رو با مدل‌هایی که از خودشون درست کردند، حل کنند. اینجا دوباره به نوعی «انتخاب طبیعی» داروین اتفاق می‌افته و مدل‌هایی که بهتر عمل می‌کنند، جا افتاده‌تر و شناخته‌تر میشن و مدل‌هایی که بد عمل می‌کنند، فراموش میشن. 

به نظرم یکی از بزرگترین تلاش‌هایی که تو چند دهه گذشته تو یادگیری ماشین داشتیم، همین بوده که یک سری آدم محقق نشستن مدل‌های مختلف رو ساختند و دیدند کدوم‌ها خوب عمل می‌کنند. 

تو این فرآیند خیلی وقت‌ها از شهودشون از فرمول‌های ریاضی کمک گرفتند. مثلاً ذات لگاریتم این هست که عددهای خیلی بزرگ رو کوچیک می‌کنه و عددهای خیلی کوچیک رو بزرگ می‌کنه. 

هر وقت در فرمولی دیدند که عددهای خیلی کوچیکی داشتند که چندان قابل مقایسه نیستند، یک لگاریتم پشتش می‌گذارند و می‌بینند که مدل بهتر جواب داد. پس از لگاریتم بیشتر و بیشتر استفاده می‌کنند. 

دقت کنید که اینجا هیچ تضمینی نمی‌دهیم که این مدل حتماً در ۹۵ درصد مواقع کار خواهد کرد. کسانی که با روش های آماری آشنا هستند حتما با p-value و مفاهیم مشابه آشنا هستند. اونجا فضای فکری اینه که مثلاً بتونیم بگیم با اطمینان ۹۵ درصد، داده در فلان بازه هست.  

اما در اکثر یادگیری ماشین به معنای مدرن‌اش همچین گزاره‌های نمی‌گن. همین که مدل‌ بتونه روی داده‌های آموزش (و داده‌های تست) خوب عمل کنه، کافی خواهد بود. بنابراین اثبات ریاضی‌ای پشت مدل‌ها نیست و بیشتر جنس تجربی داره. 

> اینجا مسئله ارزیابی مدل هم هست و به سادگی نمیشه گفت که کدوم مدل بهتر هست. نیاز هست روش سیستماتیکی برای ارزیابی مدل‌ها داشته باشیم ولی فعلا نمی‌خوام وارد این بحث بشم. 

تو این فرآیند پیچیده‌کردن مدل می‌تونید هر چقدر دوست داشتید پیش برید به شرطی که منابع کافی برای یادگرفتن بهترین وزن‌ها رو داشته باشید؛ چون همون‌طور که گفتم یادگرفتن وزن‌ها، نیاز به روش‌های بهینه‌سازی داره و این روش‌ها معمولا خیلی منابع مصرف می‌کنند. 

در بدترین حالت می‌تونید در نظر بگیرید که همه پارامترهای مدل تست بشن تا ببینیم کدوم بهتر عمل می‌کنه. در همون فرمول خطی ساده فرض کنید همه wها رو برداریم و تست کنیم. اینجا حتی لازم نیست بهترین وزن‌ها رو پیدا کنیم. بلکه اگر بتونیم وزن‌هایی پیدا کنیم که به اندازه کافی مناسب هستند هم برامون مناسب هست. 

این کاری هست که به نظر من خداوندگار طبیعت هم در طول میلیاردها سال انجام داده. مولکول‌ها (و بعداً سلول‌های) مختلف در طول میلیاردها سال با روش‌های مختلف کنار هم قرار گرفتند و سعی کردند یک پارامتر به نام «بقا» رو بهینه کنند. اون چیزی که تونسته بیشتر زنده بمونه، انتخاب شده و بقیه از بین رفتند.

فکر می‌کنم فرآیند تکامل موجودات در زیست شناسی خیلی شبیه فرآیند تکامل مدل‌های هوش‌مصنوعی هست. هر دو یک جستجوی کور در فضای بسیار بزرگ هستند. یکی داره تو فضای موجودات مختلف، دنبال بهینه‌ترین موجود می‌گرده. دیگری داره تو فضای مدل‌های مختلف، دنبال بهترین مدل می‌گرده.

برگردیم به بحث خودمون. 

تو فرآیند پیچیده‌تر فکر کردن می‌تونید هر چقدر دوست داشتید پیش برید و در واقع یکی از مهم‌ترین روند‌های یادگیری ماشین همین پیچیده‌تر کردن مدل‌ها بوده (که در ادامه این روند به مدل‌های یادگیری عمیق می‌رسیم).

زمانی مدل‌ها چند صد وزن داشتند. بعد تعداد وزن‌ها کم‌کم به چند صدهزار و چند میلیون افزایش پیدا کرد. الان بزرگترین مدل‌ها در حد چند صد میلیارد پارامتر دارند. 

برای آموزش دادن این غول‌های چند صد میلیاردی، هزاران GPU (یا TPU) قدرتمند رو کنار هم قرار میدن و سعی می‌کنند وزن‌های مدل‌هایی که خودشون درآوردند رو استخراج کنند. 

اون مدل چند صد میلیاردی هم چیز پیچیده‌ای نیست. یک سری تابع ریاضی عجیب غریب رو برمی‌داریم و به هم وصل می‌کنیم و مدل رو آموزش می‌دیم. حتی تو اون سطح هم **ریاضیات ما** فرقی نمی‌کنه. همچنان مدل‌ ما یک سری وزن عددی یاد می‌گیره و ورودی خروجی عددی می‌گیره. 

اما Train کردن همچین غول‌هایی کار هر کسی نیست. چالش‌های زیادی داره و به قول شاعر:

کار هر بز نیست خرمن کوفتن / گاو نر می‌خواد و مرد کهن

> این شعر رو چند وقت پیش دیدم و خیلی ازش خوشم اومد و مدام با خودم تکرار می‌کنم :) 

حاشیه زیاد رفتم. 

البته بحثم تموم نشده و هنوز میشه راجع به ادامه این روند بزرگ‌ترکردن مدل‌ها در یادگیری ماشین صحبت کرد و به مدل‌های یادگیری عمیق رسید. ولی دوست دارم روش‌های یادگیری عمیق (Deep Learning) رو جداگانه مفصل‌تر توضیح بدم (که در آینده نزدیک انجامش می‌دم).

اگر بخوام کل بحثم رو خلاصه کنم، من **یادگیری ماشین** رو بدست آوردن **تابعی بهینه** یا **مدلی بهینه** از بین توابع موجود با استفاده از **داده** می‌بینم. 

امیدوارم که صحبت‌هام واضح بوده باشه و قابل‌فهم.
