---
title: مدل‌های زبانی بزرگ چگونه ساخته شدند؟ - اپیزود نهم ایستگاه هوش مصنوعی
date: 2024-06-15 22:00:00 +03:30
fatags:
  - پادکست
  - ایستگاه_هوش_مصنوعی
cover:
  image: /podcast/AI_Station-v2.jpg
---

### خلاصه این قسمت

سلام. من امیر پورمند هستم و این قسمت نهم از ایستگاه هوش مصنوعیه. تو قسمت‌های قبل راجع به مدل‌های زبانی بزرگ حرف‌هایی زدیم ولی هرگز نگفتم که مدل زبانی چیه و چطوری درست شده. 

تو این قسمت می‌خوام راجع به این صحبت کنم. واقعاً هم نمی‌خوام بحث تئوری کنم. می‌خوام راجع به این‌ها صحبت کنم که وقتی قسمت‌های بعد راجع به نقاط ضعف و محدویت‌های مدل‌های زبانی صحبت کردم، یه ایده‌ای داشته باشید که چرا این نقاط ضعف بوجود اومدند یا حتی اینطوری خودتون می‌تونید راجع به کاربردهای این مدل‌ها تو صنعت خودتون بهتر فکر کنید. 

در واقع این قسمت معرفی مدل‌های زبانی بزرگ بر مبنای یک داستانه. داستان دانش‌آموزی که میره دبستان، خوندن و نوشتن یاد می‌گیره. بعد تو دبیرستان، یک سری مفاهیم رو از بر می‌کنه و تو دانشگاه نحوه تعامل با آدم‌ها رو یاد می‌گیره. 

همچنین قبلاً هم این پست راجع به مدل‌های زبانی نوشتم و بعضی چیزهایی که میگم رو اون‌جا با شکل توضیح دادم. در واقع یک چیز رو با دو بیان مختلف گفتم:

[مدل‌های زبانی بزرگ و نحوه آموزش آن‌ها | گاه‌نوشته‌های امیرپورمند](https://aprd.ir/large-language-models-training/)

### شنیدن اپیزود

{{< podcast_links >}}

<iframe src="https://castbox.fm/app/castbox/player/id5618013/id710713388?v=8.22.11&autoplay=0" frameborder="0" width="100%" height="500"></iframe>


### پیش‌ مقدمه
واقعیتش تو این پادکست معتقدم که نباید تا حد امکان از ژارگون‌ها و اصطلاحات تخصصی استفاده کنم. علتش هم ساده‌ است. علت اینه که اصطلاحات تخصصی زود به فراموشی سپرده می‌شن ولی هر چی هم یادتون بره، آنالوژی و مقایسه یادتون می‌مونه. 

اینه که قطعاً چیزهایی که اینجا می‌گم ساده‌سازی‌های خیلی زیادی از نظر علمی داخل‌شون وجود داره و اگر بخواید خیلی دقیق‌ بشید، بهتره برید کورس درست حسابی بگذرونید. 
### زبان و مدل‌سازی زبانی

زبان یکی از بهترین اختراعات بشره و فهم زبان طبیعی برای کامپیوتر چندان کار ساده‌ای نیست. از قدیم الایام علمای کامپیوتر دنبال نرم‌افزاری بودند که بتونه زبان‌های ما رو بخونه و بنویسه و صحبت کنه. 

ما برای فهم زبان خود کامپیوتر، کامپایلر داریم که کامپیوتر بتونه زبان‌های برنامه‌نویسی رو به سادگی بفهمه؛ اما اون زبان‌ها خیلی ساده ان چون مجموعه گرامرهای زبان‌شون کاملاً محدوده. 

ولی زبان آدمیزاد گرامرش خیلی پیچیده‌تره. ما سال‌ها تو دبیرستان «زبان فارسی» خوندیم. نصف قواعد فارسی رو هم یاد نگرفتیم. ولی داریم صحبت می‌کنیم. خیلی از ماها با اون قواعد جلو نمی‌ریم و خودمون به سبک خودمون صحبت می‌کنیم. هیچ مشکلی هم نداره. و اتفاقاً همین هست که زبان طبیعی رو پیچیده می‌‌کنه. 

### تاریخچه مدل‌های زبانی
اگر بخوام به قدمت بحث یک اشاره‌ای بکنم حدوداً از ۱۹۸۰ ([+](https://books.google.com/ngrams/graph?content=Expert+Systems%2C+Natural+Language+Processing&year_start=1800&year_end=2019&corpus=en-2019&smoothing=3)) تلاش‌هایی برای مدل‌‌سازی دانش (و زبان انسانی) شکل گرفته. از قدیم هم یک سری‌ها بودند که می‌خواستند دانش‌ انسانی رو بصورت کاملاً سیستماتیک داخل کامپیوتر آورد. و ایده‌شون این بود که یک سری مجموعه قواعد درست کنیم که همه حالات دانش رو در بربگیره. بعد می‌رفتند با آدم‌های «خبره» تو هر حوزه صحبت می‌کردند که بتونند دانش‌شون رو با یک سری قاعده کاملاً محدود داخل کامپیوتر بیارند. بهش میگن «سیستم خبره». 

اسمش قشنگه ها. ولی خیلی زمان‌بره که بتونی کل دانش بشری رو این‌طوری داخل یک سری قواعد به زبان کامپیوتر بنویسی. بعد اصلاً دانش بشری هی داره میره جلو. چه هزینه و انرژی‌ای بگذاریم که دستی این‌کار رو انجام بدیم؟

این بود که کم‌کم روش‌های دیگه برای «مدل‌سازی» دانش و زبان بشری درست شد. روش‌هایی که تو فیلد پردازش زبان‌های طبیعی (NLP) وجود دارند. 

ایده این بود که بریم از روش‌های یادگیری عمیق استفاده کنیم. چرا من بیام یک سری اصول به کامپیوتر یاد بدم؟ من بهش راهنمایی کنم خودش یاد بگیره. 

اینجا یک سیر تکاملی‌ای اتفاق می‌افته که کلی مدل برای فهم زبان این وسط بوجود میان و حذف میشن. اون خودش یک اپیزوده برای خودش. تاریخچه فیلد NLP. 

خلاصه‌اش اینه که در طی یک دهه کار عمیق روی این فیلد و سعی و خطا، فهمیدند که میشه زبان‌های طبیعی رو با روشی کاملاً اتوماتیک به کامپیوتر یاد داد و هر چی «مدل‌»مون تو اینجا بزرگ‌تر باشه، انگار بهتر می‌تونه زبان طبیعی رو یاد بگیره. 

حالا بریم ببینیم این مدل بزرگ چطوری بوجود اومده؟ برای این می‌خوایم براتون یک داستان تعریف کنم و مدل‌های زبانی رو به «بچه آدمیزاد» تشبیه کنم. بچه‌ای که میره دبستان و بعد میره دبیرستان و کنکور میده و وارد دانشگاه میشه و نهایتاً وارد بازار کار میشه! می‌خوایم ببینیم فرآیند آموزش LLM کجاها به به فرآیند آموزشی رسمی آدم‌ها شبیه شده! 
### دوره دبستان (Pre-training)
ما تو اول دبستان چی یاد می‌گیریم؟ یاد می‌گیریم که زبان از بخش‌های کوچیک‌تری درست شده. جمله، کلمه و حرف. 

یکی از کارهایی که تو دبستان بهمون می‌گفتند انجام بدیم این بود که «جاهای خالی را با کلمات مناسب پر کن». (Masked Language Modeling). 

یک سری دانشمندان به این فکر افتادند که بیایم به کامپیوتر هم به همین روش «زبان» یاد بدیم. 

مثلاً جملات ویکی‌پدیا رو برداریم. ۱۰ ۱۵ درصد کلماتش رو بصورت کاملاً تصادفی، خالی می‌کنیم. بعد مدل رو ملزم می‌کنیم که جای خالی رو با کلمات مناسب پر کنه! 

یعنی مثلاً جمله «آب در دمای ۱۰۰ درجه سانتی‌گراد به جوش میاد» رو در نظر بگیرید. تک‌تک کلمات این جمله رو میشه بصورت تصادفی حذف کرد و به مدل بگیم حدس بزنه. 

یکی دو تا هم نه ها. میلیاردها جمله تو سطح اینترنت داریم. مدل رو مجبور می‌کنیم که تک‌تک جملات رو حدس بزنه. پس ورودی خروجی کاملاً مشخصه. ورودی یک جمله‌ است که جای خالی داره. خروجی اون کلمه خاصه که تو انداختیم. کل کلمات دیکشنری هم بهش می‌دیم و میگیم که از بین این‌ها انتخاب کن.

قطعاً اوایلش مدل هیچی بلد نیست و همه جواب‌ها رو اشتباه می‌ده. اما کم‌کم یاد می‌گیره. انقدر تو سرش می‌زنیم تا یاد می‌گیره. حالا هر اسمی دوست دارید روش بگذارید. بگید اصلاً حفظ می‌کنه. ولی بالاخره جواب ما رو می‌تونه بده. 

خوبی این تسک اینه که برای ما راحته و برای کامپیوتر سخت! یعنی نیاز نیست من برم کار عجیب غریبی انجام بدم. من جملات زبانی رو میدم و کاملاً اتوماتیک یه سری کلماتش رو حذف می‌کنم. ولی برای مدل بدبخت این کار سخته. او هست که باید از بین میلیون‌ها کلمه داخل زبان، یک کلمه رو انتخاب کنه! بدبخت رو هیچ وقت هم تشویق نمی‌کنیم و همیشه به شدت خطایی که انجام داده، تو سرش می‌زنیم (اسم تابعش Loss Function هست).

همین کار به قدرت سخت‌افزاری بسیار عظیمی نیاز داره و اتفاقاً مدل اکثر چیزهایی که یاد می‌گیره هم توی همین قسمت هست. 

یه اسم داره اصلاً این. یادگیری خود نظارتی (Self-Supervised). یعنی مدل بتونه به خودش چیز یاد بده. جاهایی که هزینه برچسب‌زدن انسانی بسیار بالاست این‌کار می‌تونه خیلی کمک کنه. 

خیلی جاها از این ایده برای آموزش مدل‌ها استفاده میشه. مثلاً فرض کنید می‌خواید یه مدل داشته باشید که عکس سیاه سفید رو بتونه رنگی کنه. میشه از همین ایده استفاده کرد. یه عالمه تصویر رنگی تو اینترنت پیدا می‌کنیم. خودمون سیاه سفیدش می‌کنیم. سیاه سفید کردن تصویر که کاری نداره. بعد به مدل می‌گیم که سعی کن خروجی رنگی‌ای اولیه رو تولید کنی! 

شاید به نظر بیاد که چه کار ساده‌ای هست! چرا انتظار داری که با پرکردن جاهای خالی، مدل، زبان فارسی رو یاد بگیره! کمی بهش فکر کنید. 

تو جملات ساده که حدوداً مشخصه. مدل کم‌کم با این روش قواعد زبانی رو بصورت ضمنی یاد می‌گیره. یاد می‌گیره که تو هر متنی از چه کلماتی با احتمال بیشتر استفاده می‌شه و یاد می‌گیره کجا چه کلمه‌ای می‌تونه قرار بگیره. 

اما بیاید به یک مثال فکر کنیم (از [این](https://arxiv.org/abs/2303.18223) مقاله). فکر کنید یک رمان جنایی می‌خونید. خط داستانی رو دنبال می‌کنید. تمام سرنخ‌ها رو دنبال می‌کنید. اسم‌ شخصیت‌ها. کارهایی که انجام دادند و تو خط آخر اون رمان، نوشته که «بنابراین نام قاتل جای‌خالی است». آیا باز هم تشخیص جای خالی آسونه؟ 
### دوره دبیرستان (Intruction-Tuning)
تو دوره دبیرستان دیگه بچه‌مون بزرگ شده. الان می‌تونه «جای خالی رو با کلمات» مناسب پر کنه و کلمه بعدی در یک جمله رو حدس بزنه. 

من تو بخش قبلی این قسمت «حدس زدن کلمه بعدی» رو تو انداختم ولی تقریباً همونه. شما چه کلمه آخر یک عبارت رو حدس بزنی، چه کلمه وسطش رو حدس بزنی. ولی چه کنیم که علمای دیپ لرنینگ برای این‌ها نام‌های متفاوتی گذاشتند. به یکیش میگن Masked Lanauge Modeling. به اون یکی میگن Next Token Prediction. 

خلاصه این که الان مدل خیلی از دانش انسانی رو یاد گرفته. فقط هنوز روشی برای بیانش نداره. یعنی مثلاً اگر بگید «قانون جای‌خالی نیوتون راجع به شتاب جسم صحبت می‌کنه» می‌تونه بفهمه که جای‌خالی باید دوم باشه. یعنی کلی چیز یاد گرفته اما هنوز روش ارتباطش جای خالی هست. 

الان می‌خوایم روش ارتباطی‌اش رو سؤال جواب کنیم. میایم همون کاری که معلم‌های دبیرستان با ما می‌کردند باهاش می‌کنیم. یک سری سؤال جواب بهش میدیم و میگیم عیناً کلمه به کلمه باید مثل من جواب بدی. 

مثلاً اگر بهت گفتم که «تعریف سازمان ملل متحد راجع به خانواده چیست» باید عیناً چیزی که نوشته رو جواب بدی. همون کار نسبتاً بی‌خاصیتی که ما هم تو دوره دبیرستان انجام می‌دادیم و کلی چیز حفظ می‌کردیم. 

الان هم از مدل همین انتظار رو داریم. یعنی خودمون میریم مجموعه‌ای از میلیون‌ها سؤال جواب درست می‌کنیم و به مدل می‌گیم و می‌گیم که سعی کن عین من جواب بده. این مجموعه‌ها الان تو همه حوزه‌ها درست شدند و تقریباً تو همه زبان‌ها دیتاست‌هایی پر از سؤال و جواب داریم. حالا این پرسش و پاسخ‌ها می‌تونه حاوی شیمی، فیزیک، ریاضی و منطق و هر سؤال دیگه‌ای باشه. مهم نیست. 

حالا از مدل انتظار تولید خروجی جمله داریم اما یادتون هست که مدل ما فقط بلده کلمه کلمه جواب بده! اما اینم راه حل داره. 

فرض کنید. از مدل می‌پرسیم که «سه رنگ اصلی چه چیزهایی هستند». جوابی که انتظار داریم اینه که «سه رنگ اصلی قرمز، آبی و زرد هستند» و به مدل یاد می‌دیم که همین‌طور خروجی‌ای تولید کنه. 

منتهی مشکلی که وجود داره اینه که مدل فقط بلده خروجی رو کلمه به کلمه تولید کنه. مثلاً در نظر بگیرید که سؤال «سه رنگ اصلی چه چیزهایی هستند» رو به عنوان ورودی به مدل می‌دیم و می‌گیم کلمه بعدی رو پیش‌بینی کن. اینجا فکر می‌کنه ببینه محتمل‌ترین کلمه بعد از این جمله چیه؟ 

خروجی میده. میگه «سه». بعد از اون دوباره «سؤال» و قسمتی از جواب رو که تولید کرده بهش می‌دیم و بهش می‌گیم که محتمل‌ترین کلمه بعد از این چیه؟ 

همین جور میره جلو. یعنی وقتی بهش میگی که سه رنگ اصلی چیه برای این که خروجی رو تولید کنه، چند بار رفت و برگشت داره. 

اگر هم دقت کرده باشید وقتی با مدل‌های زبانی کار می‌کنید اینها خروجی رو کم‌کم میدن. علتش دقیقاً همینه. مدل زبانی نمی‌تونه خروجی یک‌جا تولید کنه. توکن به توکن تولید می‌کنه (البته تو پرانتز بگم که واحدش در واقع توکن هست و با کلمه فرق داره ولی اینجا فرض کنید هر توکن یک کلمه است). 

تو این بخش برای یاددادن به مدل صبر می‌کنیم تا مدل کامل خروجی‌اش رو تولید کنه، بعد بهش می‌گیم که خروجی‌ای که تولید کردی اشتباه بود! عین من تولید کن و خب اوایل قطعاً اشتباهات زیادی مرتکب میشه ولی هر چی جلوتر میره، بهتر و دقیق‌تر می‌تونه به سؤالات ما جواب بده. 

پس الان از مدلی که بلد بود صرفاً کلمه بعدی رو پیش‌بینی کنه و جای خالی رو پر کنه، به مدلی رسیدیم که وقتی سؤال ازش می‌پرسیم می‌تونه جواب بده. 

به نظر میاد که مدل اکثر دانشی که یاد گرفته رو تو همون فاز اول یاد گرفته ولی تو این فاز یاد می‌گیره، چطوری حالت سؤال جواب باهامون گفتگو کنه و می‌تونید ازش سؤال بپرسید و جواب بگیرید. 
### دوره دانشگاه (Alignment-Tuning)
تا الان بچه‌مون دبیرستانش رو تموم کرد و کنکورش رو هم داد. حالا می‌خواد وارد دانشگاه بشه و اینجا نیازه که «تعامل» و «ارتباط درست» با آدم‌ها رو یاد بگیره. 

یه مهارتی که کسی که دانشگاه رفته یاد می‌گیره اینه که چطوری میشه کلی‌گویی کرد و راجع به یک سری مسائل (مثلاً مسائل مذهبی یا سیاسی یا جنسیتی) نظرات کلی داد. چون اختلاف وجود داره. 

تو این فاز دیگه قرار نیست که دقیقاً بهش دیکته کنیم که عین من جواب بده؛ ولی ازش انتظار داریم که بتونه جواب‌هایی تولید کنه که «کمک‌کننده» (Helpful)، «صادقانه» (Honest) و «بی‌خطر» (Harmless) باشند (بر اساس [این مقاله](https://arxiv.org/abs/2303.18223)).

کمک‌کننده یعنی این که باید واقعاً سعی کنه، خروجی‌ای تولید کنه که تو حل کردن مسائل به کار ما بیاد. 
صداقت یعنی این که باید سعی کنه خروجی‌اش تا حد امکان دقیق باشه و از خودش چیزی توهم نزنه. به طور خاص، اگر سعی کنه جوابی که تولید می‌کنه، مقداری از عدم قطعیت داشته باشه خیلی کمک می‌کنه. 

دیدید بعضی‌ها وقتی دارند حرف‌ می‌زنند، جوری حرف می‌زنند که هیچ‌کی بدش نیاد. مثلاً میگن فلان ایده ممکنه بعضی جاها مفید باشه و ممکنه هم ضررهای خاصی داشته باشه که من ازش مطلع نیستم. 

این فاز کلی‌گویی رو باید به مدل اضافه کنیم که باعث بشه، خروجی‌هایی تولید کنه که بیشتر مطابق ما باشه. این تو بحث‌های علوم انسانی لازمه چون هیچ‌چیزی اونجا مطلق نیست. همه چیز قابل بحثه و دانشمندان تو کلیاتش هم اختلاف نظر دارند و خیلی خوبه که مدل هم یاد بگیره مطلق حرف نزنه. 

سومین بحثش هم «بی‌‌خطر» بودن هست. یعنی به هیچ‌کس نباید توهین کنه. بدش نیاد. یا مثلاً طرف اگر بهش میگه که چطوری بمب درست کنم، نباید جواب بده. 

این فاز سوم بعضی‌جاها گفته میشه که ممکنه به کیفیت مدل هم کمی لطمه بزنه اما می‌ارزه! چون فرض کنید یه شرکت درست حسابی می‌خواد از این LLMها تو محصول‌اش استفاده کنه. نمیشه که مدل نظرات رادیکال راجع به فلان شخصیت سیاسی یا مذهبی داشته باشه. مدل باید بی‌نظر باشه. 

برای این فاز سوم، روش‌های خیلی زیادی وجود داره و حوزه‌ای هست که به شدت داره روش تحقیق می‌شه. من فقط به یه روش اشاره می‌کنم. روشی تحت عنوان «یادگیری تقویتی با فیدبک انسانی» یا (Reinforcement learning from human feedback). 

تو این روش دیگه به مدل دیکته نمی‌کنیم که دقیقاً مثل من جواب بده. دیگه مدل شخصیت محترمی هست. ما به مدل اجازه می‌دیم خروجی‌های مختلف تولید کنه و خروجی‌اش رو به انسان میدیم که «سطح‌بندی» (Ranking-based approach) کنه. و بعد بهش می‌گیم که سعی کن خروجی‌هایی تولید کنی که بیشتر مطابق میل انسان باشه. 

قاعدتاً اینجا مدل کم‌کم یاد می‌گیره که کجاها باید خیلی با احتیاط بیشتری جواب بده و چه جاهایی می‌تونه محکم‌تر و قطعی‌تر صحبت کنه. مثلاً مسئله ریاضی رو نباید بگه جواب این سؤال ممکنه رادیکال سه باشه. جواب قطعاً رادیکال سه هست. 

اما اگر بهش بگیم که فلان عقیده خاص رو نقد کن، حواسش هست که به اندازه کافی کلی‌گویی کنه. و اینجا به نظرم یک تفاوت اصلی ما آدم‌ها با این مدل‌هاست. 

آدمی که همش کلی‌گویی می‌کنه و تو هیچ حوزه‌ای هیچ نظری نداره، آدمیت خودش رو چندان نشون نداده و از سطح LLMهای الان فراتر نرفته. 

قاعدتاً اینجا فازهای آموزش مدل تموم میشه اما مدل چیزی نیست که یک‌بار آموزش بدن و بندازند کنار. مدل‌های دائما در حال یادگیری و طی‌کردن این فرآیند هستند و ما فقط اون‌ مدل‌هایی رو می‌بینیم که خیلی خوب تونستند از این فازها گذر کنند و نهایتاً تو دانشگاه نمره خیلی خیلی خوبی گرفتند. 

اما اینجا پایان ماجرا نیست. دانشجوی ما هنوز نیاز داره که به بازار کار وارد بشه و مهارت‌های بازار کار رو یاد بگیره. یعنی این مدل نیاز داره که وارد فرآیندهای شرکت بشه و یک‌جا ازش استفاده بشه. 

حالا این که وارد کردنش به شرکت چقدر چالش داره و با چه مسائلی دست و پنجه نرم‌ خواهد کرد و چطوری میشه حل‌شون کرد، چیزی هست که قسمت‌های بهش خواهیم پرداخت. 

### منابع
برای تهیه این قسمت هم از مقالات آکادمیک و وبلاگ‌های زیر استفاده کردم که اگر خواستید می‌تونید بیشتر بخونید. این‌طوری هم نیست که لزوماً همه بخش‌های این‌ها رو خونده باشم ولی بالاخره لینک‌هایی هست که موقع فکرکردن به این قسمت بهشون سرزدم و ازشون یاد گرفتم. 

- [\[2303.18223\] A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
- [\[2307.06435\] A Comprehensive Overview of Large Language Models](https://arxiv.org/abs/2307.06435)
- [\[2402.06196\] Large Language Models: A Survey](https://arxiv.org/abs/2402.06196)
- [What Are Expert Systems? | Baeldung on Computer Science](https://www.baeldung.com/cs/expert-systems)
- [history - Why did expert systems fall? - Retrocomputing Stack Exchange](https://retrocomputing.stackexchange.com/questions/6456/why-did-expert-systems-fall)
